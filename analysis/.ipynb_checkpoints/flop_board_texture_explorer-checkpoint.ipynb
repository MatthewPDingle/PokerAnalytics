{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flop Board Texture Explorer\n",
    "\n",
    "Analyze flop continuation bets across common board textures using the same sizing buckets and grouped summaries as the flop c-bet explorer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Texture Definitions\n",
    "\n",
    "- **Rainbow** \u2013 three distinct suits.\n",
    "- **Monotone** \u2013 all cards share the same suit.\n",
    "- **Two-Tone** \u2013 exactly two suits are present (a 2-1 split).\n",
    "- **Paired** \u2013 the flop contains a pair (at least two cards of the same rank).\n",
    "- **Connected** \u2013 the highest and lowest ranks are at most four apart (treating A as either high or low).\n",
    "- **Ace-High** \u2013 an Ace appears and it is the highest card on the board.\n",
    "- **Low Boards** \u2013 all cards are Ten or lower.\n",
    "- **High Boards** \u2013 at least two cards are Broadway ranks (Ace, King, Queen, Jack).\n",
    "\n",
    "Textures are evaluated independently, so a single board can appear in multiple tables when it satisfies multiple definitions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "def _locate_project_root() -> Path:\n",
    "    current = Path().resolve()\n",
    "    for candidate in (current, *current.parents):\n",
    "        if (candidate / \"AGENTS.md\").exists():\n",
    "            return candidate\n",
    "    raise FileNotFoundError(\"Repository root not found from notebook location.\")\n",
    "\n",
    "PROJECT_ROOT = _locate_project_root()\n",
    "del _locate_project_root\n",
    "\n",
    "DB_CANDIDATES = [\n",
    "    Path(r\"T:\\Dev\\ignition\\drivehud\\drivehud.db\"),\n",
    "    Path(\"/mnt/t/Dev/ignition/drivehud/drivehud.db\"),\n",
    "    PROJECT_ROOT / \"drivehud\" / \"drivehud.db\",\n",
    "]\n",
    "\n",
    "for candidate in DB_CANDIDATES:\n",
    "    if candidate.exists():\n",
    "        DB_PATH = candidate\n",
    "        break\n",
    "else:\n",
    "    checked = os.linesep.join(str(p) for p in DB_CANDIDATES)\n",
    "    message = \"Database not found. Checked:\" + os.linesep + checked\n",
    "    raise FileNotFoundError(message)\n",
    "\n",
    "CACHE_PATH = PROJECT_ROOT / \"analysis\" / \"cache\" / \"cbet_events.json\"\n",
    "FORCE_RELOAD = False\n",
    "\n",
    "if not DB_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Database not found at {DB_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from analysis.cbet_utils import (\n",
    "    BASE_PRIMARY_CATEGORIES,\n",
    "    DEFAULT_DRAW_FLAGS,\n",
    "    load_cbet_events,\n",
    "    summarize_events,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration & helpers ---\n",
    "RAW_BUCKET_BOUNDS = [\n",
    "    (0.00, 0.25),\n",
    "    (0.25, 0.40),\n",
    "    (0.40, 0.60),\n",
    "    (0.60, 0.80),\n",
    "    (0.80, 1.00),\n",
    "    (1.00, 1.25),\n",
    "    (1.25, float(\"inf\")),\n",
    "]\n",
    "\n",
    "def _bucket_label(low: float, high: float) -> str:\n",
    "    if high == float(\"inf\"):\n",
    "        return f\">={low:.2f}\"\n",
    "    return f\"[{low:.2f}, {high:.2f})\"\n",
    "\n",
    "BUCKETS = [(low, high, _bucket_label(low, high)) for (low, high) in RAW_BUCKET_BOUNDS]\n",
    "del _bucket_label\n",
    "\n",
    "PRIMARY_GROUPS = {cat: [cat] for cat in BASE_PRIMARY_CATEGORIES}\n",
    "DRAW_FLAGS = DEFAULT_DRAW_FLAGS.copy()\n",
    "\n",
    "DEFAULT_DROP_COLUMNS = {\"Range\", \"Made Flush\", \"Made Straight\"}\n",
    "\n",
    "GROUPED_PRIMARY_ORDER = [\n",
    "    (\"Events\", None),\n",
    "    (\"Air\", [\"Air\"]),\n",
    "    (\"Weak Pair\", [\"Underpair\", \"Bottom Pair\", \"Middle Pair\"]),\n",
    "    (\"Top Pair\", [\"Top Pair\"]),\n",
    "    (\"Overpair\", [\"Overpair\"]),\n",
    "    (\"Two Pair\", [\"Two Pair\"]),\n",
    "    (\"Trips/Set\", [\"Trips/Set\"]),\n",
    "    (\"Monster\", [\"Straight\", \"Flush\", \"Full House\", \"Quads\"]),\n",
    "    (\"Draw\", [\"Flush Draw\", \"OESD/DG\"]),\n",
    "]\n",
    "\n",
    "def _gradient_cmap(base_color: str) -> LinearSegmentedColormap:\n",
    "    name = f\"gradient_{base_color.strip('#')}\"\n",
    "    return LinearSegmentedColormap.from_list(name, ['#ffffff', base_color])\n",
    "\n",
    "def _summary_records_to_df(records, drop_columns=None):\n",
    "    if not records:\n",
    "        return pd.DataFrame()\n",
    "    df = pd.DataFrame(records)\n",
    "    drop_columns = drop_columns or set()\n",
    "    for col in drop_columns:\n",
    "        if col in df.columns:\n",
    "            df = df.drop(columns=[col])\n",
    "    df = df.set_index(\"Bucket\").T\n",
    "    df = df.apply(pd.to_numeric, errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "def _style_heatmap(df, title, base_color=\"#1f77b4\", fmt=\"{:.1f}\", special_columns=None):\n",
    "    if df.empty:\n",
    "        return None\n",
    "    data_index = df.index.difference([\"Events\"])\n",
    "    styled = df.style.format(fmt)\n",
    "    if not data_index.empty:\n",
    "        styled = styled.background_gradient(\n",
    "            cmap=_gradient_cmap(base_color),\n",
    "            axis=None,\n",
    "            subset=pd.IndexSlice[data_index, :]\n",
    "        )\n",
    "    if special_columns:\n",
    "        first = special_columns[0]\n",
    "        if first in df.columns:\n",
    "            col_idx = df.columns.get_loc(first)\n",
    "            styles = [\n",
    "                {\n",
    "                    'selector': f'th.col_heading.level0.col{col_idx}',\n",
    "                    'props': [('border-left', '2px solid #64748b')],\n",
    "                },\n",
    "                {\n",
    "                    'selector': f'td.col{col_idx}',\n",
    "                    'props': [('border-left', '2px solid #64748b')],\n",
    "                },\n",
    "            ]\n",
    "            styled = styled.set_table_styles(styles, overwrite=False)\n",
    "    return styled.set_caption(title)\n",
    "\n",
    "def _aggregate_grouped(df, group_order):\n",
    "    rows = []\n",
    "    for label, members in group_order:\n",
    "        if members is None:\n",
    "            if \"Events\" in df.index:\n",
    "                rows.append((label, df.loc[\"Events\"]))\n",
    "            continue\n",
    "        available = [member for member in members if member in df.index]\n",
    "        if not available:\n",
    "            continue\n",
    "        rows.append((label, df.loc[available].sum()))\n",
    "    if not rows:\n",
    "        return pd.DataFrame()\n",
    "    data = pd.DataFrame([series for _, series in rows], index=[label for label, _ in rows])\n",
    "    return data\n",
    "\n",
    "def display_heatmap_tables(summary_records, title, *, base_color=\"#1f77b4\", group_color=\"#2ca25f\", special_rows=None):\n",
    "    records = list(summary_records)\n",
    "    special_columns = []\n",
    "    if special_rows:\n",
    "        records.extend(special_rows)\n",
    "        special_columns = [row['Bucket'] for row in special_rows if row.get('Bucket')]\n",
    "    base_df = _summary_records_to_df(records, DEFAULT_DROP_COLUMNS)\n",
    "    styled = _style_heatmap(base_df, title, base_color=base_color, special_columns=special_columns)\n",
    "    if styled is not None:\n",
    "        display(styled)\n",
    "    grouped_df = _aggregate_grouped(base_df, GROUPED_PRIMARY_ORDER)\n",
    "    styled_grouped = _style_heatmap(grouped_df, f\"{title} (Grouped)\", base_color=group_color, special_columns=special_columns)\n",
    "    if styled_grouped is not None:\n",
    "        display(styled_grouped)\n",
    "\n",
    "def _filtered_primary_groups(subset_records):\n",
    "    available = {event['primary'] for event in subset_records}\n",
    "    groups = {}\n",
    "    for name, members in PRIMARY_GROUPS.items():\n",
    "        members_in_subset = [cat for cat in members if cat in available]\n",
    "        if members_in_subset:\n",
    "            groups[name] = members_in_subset\n",
    "    if not groups:\n",
    "        for cat in sorted(available):\n",
    "            groups[cat] = [cat]\n",
    "    return groups\n",
    "\n",
    "def _build_special_rows(subset_records):\n",
    "    specials = []\n",
    "    special_specs = [\n",
    "        (\"All-In\", lambda event: event.get(\"is_all_in\")),\n",
    "        (\"1 BB\", lambda event: event.get(\"is_one_bb\")),\n",
    "    ]\n",
    "    for label, predicate in special_specs:\n",
    "        filtered = [event for event in subset_records if predicate(event)]\n",
    "        if not filtered:\n",
    "            continue\n",
    "        groups = _filtered_primary_groups(filtered)\n",
    "        specials.extend(\n",
    "            summarize_events(\n",
    "                filtered,\n",
    "                [(0.0, float(\"inf\"), label)],\n",
    "                groups,\n",
    "                DRAW_FLAGS,\n",
    "            )\n",
    "        )\n",
    "    return specials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = load_cbet_events(DB_PATH, cache_path=CACHE_PATH, force=FORCE_RELOAD)\n",
    "print(f\"Loaded {len(events)} flop c-bet events.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_all = summarize_events(events, BUCKETS, PRIMARY_GROUPS, DRAW_FLAGS)\n",
    "special_all = _build_special_rows(events)\n",
    "display_heatmap_tables(summary_all, \"All C-Bets\", special_rows=special_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANK_VALUES = {\n",
    "    '2': 2,\n",
    "    '3': 3,\n",
    "    '4': 4,\n",
    "    '5': 5,\n",
    "    '6': 6,\n",
    "    '7': 7,\n",
    "    '8': 8,\n",
    "    '9': 9,\n",
    "    'T': 10,\n",
    "    'J': 11,\n",
    "    'Q': 12,\n",
    "    'K': 13,\n",
    "    'A': 14,\n",
    "}\n",
    "\n",
    "BROADWAY_RANKS = {'A', 'K', 'Q', 'J'}\n",
    "\n",
    "def parse_flop_cards(card_string: str | None):\n",
    "    if not card_string:\n",
    "        return None, None, None\n",
    "    tokens = [token.strip().upper() for token in card_string.split() if token.strip()]\n",
    "    if len(tokens) != 3:\n",
    "        return None, None, None\n",
    "    suits, ranks, values = [], [], []\n",
    "    for token in tokens:\n",
    "        suit, rank = token[0], token[1]\n",
    "        if rank not in RANK_VALUES:\n",
    "            return None, None, None\n",
    "        suits.append(suit)\n",
    "        ranks.append(rank)\n",
    "        values.append(RANK_VALUES[rank])\n",
    "    return suits, ranks, values\n",
    "\n",
    "def is_connected(values):\n",
    "    if not values or len(values) != 3 or any(v is None for v in values):\n",
    "        return False\n",
    "    sorted_vals = sorted(values)\n",
    "    if sorted_vals[-1] - sorted_vals[0] <= 4:\n",
    "        return True\n",
    "    if 14 in sorted_vals:\n",
    "        alt = sorted(1 if v == 14 else v for v in values)\n",
    "        return alt[-1] - alt[0] <= 4\n",
    "    return False\n",
    "\n",
    "TEXTURE_SPECS = [\n",
    "    (\"Rainbow Flops\", lambda suits, ranks, values: len(set(suits)) == 3),\n",
    "    (\"Monotone Flops\", lambda suits, ranks, values: len(set(suits)) == 1),\n",
    "    (\"Two-Tone Flops\", lambda suits, ranks, values: len(set(suits)) == 2),\n",
    "    (\"Paired Flops\", lambda suits, ranks, values: len(set(ranks)) < 3),\n",
    "    (\"Connected Flops\", lambda suits, ranks, values: is_connected(values)),\n",
    "    (\"Ace-High Flops\", lambda suits, ranks, values: values is not None and values and 14 in values and max(values) == 14),\n",
    "    (\"Low Flops (All \u2264 Ten)\", lambda suits, ranks, values: values is not None and values and all(v <= 10 for v in values)),\n",
    "    (\"High Flops (\u22652 Broadways)\", lambda suits, ranks, values: ranks is not None and sum(1 for r in ranks if r in BROADWAY_RANKS) >= 2),\n",
    "]\n",
    "\n",
    "\n",
    "def _filter_events(predicate):\n",
    "    matched = []\n",
    "    for event in events:\n",
    "        suits, ranks, values = parse_flop_cards(event.get('flop_cards'))\n",
    "        if suits is None:\n",
    "            continue\n",
    "        if predicate(suits, ranks, values):\n",
    "            matched.append(event)\n",
    "    return matched\n",
    "\n",
    "\n",
    "def display_texture_summary(title, predicate):\n",
    "    subset = _filter_events(predicate)\n",
    "    print(f\"{title}: {len(subset)} events\")\n",
    "    if not subset:\n",
    "        return\n",
    "    summary = summarize_events(subset, BUCKETS, PRIMARY_GROUPS, DRAW_FLAGS)\n",
    "    specials = _build_special_rows(subset)\n",
    "    display_heatmap_tables(summary, title, special_rows=specials)\n",
    "\n",
    "for texture_title, texture_predicate in TEXTURE_SPECS:\n",
    "    display_texture_summary(texture_title, texture_predicate)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}