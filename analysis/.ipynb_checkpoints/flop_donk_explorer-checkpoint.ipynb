{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ec36501",
   "metadata": {},
   "source": [
    "# Flop Donk Bet Explorer\n",
    "\n",
    "Use this notebook to explore how different flop continuation-bet sizes correlate with the bettor's made hand or draw strength. Edit the configuration cell to experiment with custom sizing buckets or category groupings.\n",
    "\n",
    "Workflow:\n",
    "1. Adjust `BUCKETS`, `PRIMARY_GROUPS`, or `DRAW_FLAGS` below.\n",
    "2. Rerun the helper cell and the summary cell to see the updated breakdown.\n",
    "3. Optional: enable caching or convert events to a pandas DataFrame for ad-hoc filtering.\n",
    "\n",
    "> Buckets use left-inclusive, right-exclusive ranges (e.g. a 0.25 bet falls into [0.25, 0.40)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52238a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "def _locate_project_root() -> Path:\n",
    "    current = Path().resolve()\n",
    "    for candidate in (current, *current.parents):\n",
    "        if (candidate / \"AGENTS.md\").exists():\n",
    "            return candidate\n",
    "    raise FileNotFoundError(\"Repository root not found from notebook location.\")\n",
    "\n",
    "PROJECT_ROOT = _locate_project_root()\n",
    "del _locate_project_root\n",
    "\n",
    "DB_CANDIDATES = [\n",
    "    Path(r\"T:\\Dev\\ignition\\drivehud\\drivehud.db\"),\n",
    "    Path(\"/mnt/t/Dev/ignition/drivehud/drivehud.db\"),\n",
    "    PROJECT_ROOT / \"drivehud\" / \"drivehud.db\",\n",
    "]\n",
    "\n",
    "for candidate in DB_CANDIDATES:\n",
    "    if candidate.exists():\n",
    "        DB_PATH = candidate\n",
    "        break\n",
    "else:\n",
    "    checked = os.linesep.join(str(p) for p in DB_CANDIDATES)\n",
    "    message = \"Database not found. Checked:\" + os.linesep + checked\n",
    "    raise FileNotFoundError(message)\n",
    "\n",
    "CACHE_PATH = PROJECT_ROOT / \"analysis\" / \"cache\" / \"donk_events.json\"\n",
    "\n",
    "if not DB_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Database not found at {DB_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e4fca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import sqlite3\n",
    "import xml.etree.ElementTree as ET\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from analysis.cbet_utils import (\n",
    "    BASE_PRIMARY_CATEGORIES,\n",
    "    DEFAULT_DRAW_FLAGS,\n",
    "    available_primary_categories,\n",
    "    events_to_dataframe,\n",
    "    summarize_events,\n",
    "    response_events,\n",
    "    BET_TYPES,\n",
    "    RAISE_TYPES,\n",
    "    CALL_TYPES,\n",
    "    FOLD_TYPES,\n",
    "    parse_cards_text,\n",
    "    classify_hand,\n",
    "    extract_big_blind,\n",
    ")\n",
    "from analysis.sqlite_utils import connect_readonly\n",
    "from analysis.turn_utils import (\n",
    "    TURN_BUCKETS as TURN_BUCKETS_TURN,\n",
    "    load_turn_events as load_turn_events_turn,\n",
    "    turn_response_events as turn_response_events_turn,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_donk_events(db_path: Path, cache_path: Path | None = None, force: bool = False) -> list[dict]:\n",
    "    if cache_path and cache_path.exists() and not force:\n",
    "        with cache_path.open('r', encoding='utf-8') as fh:\n",
    "            cached = json.load(fh)\n",
    "        if cached and ('in_position' not in cached[0] or 'responses' not in cached[0]):\n",
    "            return load_donk_events(db_path, cache_path, force=True)\n",
    "        return cached\n",
    "\n",
    "    events: list[dict] = []\n",
    "    with connect_readonly(db_path) as conn:\n",
    "        conn.row_factory = sqlite3.Row\n",
    "        cur = conn.cursor()\n",
    "        cur.execute('SELECT HandHistoryId, HandNumber, HandHistory FROM HandHistories')\n",
    "        for row in cur:\n",
    "            root = ET.fromstring(row['HandHistory'])\n",
    "            big_blind = extract_big_blind(root)\n",
    "            if big_blind is None or big_blind <= 0:\n",
    "                continue\n",
    "\n",
    "            pocket_cards: dict[str, list[tuple[str, int, str]]] = {}\n",
    "            for node in root.findall('.//round[@no=\"1\"]/cards'):\n",
    "                player = node.attrib.get('player')\n",
    "                cards = parse_cards_text(node.text)\n",
    "                if player and len(cards) == 2:\n",
    "                    pocket_cards[player] = cards\n",
    "            if not pocket_cards:\n",
    "                continue\n",
    "\n",
    "            total_pot = 0.0\n",
    "            last_aggressor: str | None = None\n",
    "            donk_logged = False\n",
    "            flop_cards: list[tuple[str, int, str]] | None = None\n",
    "            flop_players_set: set[str] = set()\n",
    "            flop_actions: list[tuple[str, str]] = []\n",
    "            current_event: dict | None = None\n",
    "            responders_recorded: set[str] = set()\n",
    "            flop_total_players: int | None = None\n",
    "            pfr_has_acted = False\n",
    "\n",
    "            rounds = sorted(root.findall('.//round'), key=lambda r: int(r.attrib.get('no', '0')))\n",
    "            for rnd in rounds:\n",
    "                round_no = int(rnd.attrib.get('no', '0'))\n",
    "                if round_no == 2 and flop_cards is None:\n",
    "                    for card_node in rnd.findall('cards'):\n",
    "                        if card_node.attrib.get('type') == 'Flop':\n",
    "                            flop_cards = parse_cards_text(card_node.text)\n",
    "                            break\n",
    "                if round_no == 2 and flop_total_players is None:\n",
    "                    players_this_round = {a.attrib.get('player') for a in rnd.findall('action') if a.attrib.get('player')}\n",
    "                    flop_total_players = len(players_this_round)\n",
    "\n",
    "                for action in rnd.findall('action'):\n",
    "                    player = action.attrib.get('player')\n",
    "                    if not player:\n",
    "                        continue\n",
    "                    act_type = action.attrib.get('type')\n",
    "                    try:\n",
    "                        amount = float(action.attrib.get('sum') or 0.0)\n",
    "                    except ValueError:\n",
    "                        amount = 0.0\n",
    "\n",
    "                    if round_no == 1 and act_type in RAISE_TYPES and amount > 0:\n",
    "                        last_aggressor = player\n",
    "                    elif round_no == 2:\n",
    "                        prior_actions = list(flop_actions)\n",
    "                        flop_actions.append((player, act_type))\n",
    "                        flop_players_set.add(player)\n",
    "                        if last_aggressor and player == last_aggressor:\n",
    "                            pfr_has_acted = True\n",
    "                        if (\n",
    "                            not donk_logged\n",
    "                            and last_aggressor\n",
    "                            and player != last_aggressor\n",
    "                            and not pfr_has_acted\n",
    "                            and act_type in BET_TYPES\n",
    "                            and amount > 0\n",
    "                        ):\n",
    "                            if flop_cards and player in pocket_cards and total_pot > 0:\n",
    "                                is_all_in = act_type == '7'\n",
    "                                bet_amount = amount\n",
    "                                bet_amount_bb = bet_amount / big_blind if big_blind else None\n",
    "                                tolerance = max(1e-6, (big_blind or 0.0) * 1e-4)\n",
    "                                is_one_bb = bool(big_blind) and abs(bet_amount - big_blind) <= tolerance\n",
    "                                ratio = bet_amount / total_pot\n",
    "                                classification = classify_hand(pocket_cards[player], flop_cards)\n",
    "                                in_position = any(actor != player for actor, _ in prior_actions)\n",
    "                                event = {\n",
    "                                    'hand_number': row['HandNumber'],\n",
    "                                    'player': player,\n",
    "                                    'ratio': round(ratio, 6),\n",
    "                                    'bet_amount': bet_amount,\n",
    "                                    'bet_amount_bb': bet_amount_bb,\n",
    "                                    'bet_action_type': act_type,\n",
    "                                    'is_all_in': is_all_in,\n",
    "                                    'is_one_bb': is_one_bb,\n",
    "                                    'big_blind': big_blind,\n",
    "                                    'primary': classification['primary'],\n",
    "                                    'hole_cards': ' '.join(card for _, _, card in pocket_cards[player]),\n",
    "                                    'flop_cards': ' '.join(card for _, _, card in flop_cards),\n",
    "                                    'has_flush_draw': bool(classification['flush_draw']),\n",
    "                                    'has_oesd_dg': bool(classification['oesd_dg']),\n",
    "                                    'made_flush': bool(classification['made_flush']),\n",
    "                                    'made_straight': bool(classification['made_straight']),\n",
    "                                    'made_full_house': bool(classification['made_full']),\n",
    "                                    'in_position': bool(in_position),\n",
    "                                    'flop_players': flop_total_players or len(flop_players_set),\n",
    "                                    'responses': [],\n",
    "                                }\n",
    "                                events.append(event)\n",
    "                                current_event = event\n",
    "                                responders_recorded = set()\n",
    "                            donk_logged = True\n",
    "                        if (\n",
    "                            round_no == 2\n",
    "                            and current_event is not None\n",
    "                            and player != current_event['player']\n",
    "                            and player not in responders_recorded\n",
    "                        ):\n",
    "                            response_kind: str | None = None\n",
    "                            if act_type in FOLD_TYPES:\n",
    "                                response_kind = 'Fold'\n",
    "                            elif act_type in CALL_TYPES:\n",
    "                                response_kind = 'Call'\n",
    "                            elif act_type in RAISE_TYPES or act_type in BET_TYPES:\n",
    "                                response_kind = 'Raise'\n",
    "\n",
    "                            if response_kind:\n",
    "                                responder_primary = None\n",
    "                                responder_flush_draw = False\n",
    "                                responder_oesd = False\n",
    "                                responder_made_flush = False\n",
    "                                responder_made_straight = False\n",
    "                                responder_made_full = False\n",
    "\n",
    "                                if flop_cards and player in pocket_cards:\n",
    "                                    responder_class = classify_hand(pocket_cards[player], flop_cards)\n",
    "                                    responder_primary = responder_class['primary']\n",
    "                                    responder_flush_draw = bool(responder_class['flush_draw'])\n",
    "                                    responder_oesd = bool(responder_class['oesd_dg'])\n",
    "                                    responder_made_flush = bool(responder_class['made_flush'])\n",
    "                                    responder_made_straight = bool(responder_class['made_straight'])\n",
    "                                    responder_made_full = bool(responder_class['made_full'])\n",
    "\n",
    "                                current_event['responses'].append(\n",
    "                                    {\n",
    "                                        'player': player,\n",
    "                                        'action_type': act_type,\n",
    "                                        'response': response_kind,\n",
    "                                        'amount': amount,\n",
    "                                        'primary': responder_primary,\n",
    "                                        'has_flush_draw': responder_flush_draw,\n",
    "                                        'has_oesd_dg': responder_oesd,\n",
    "                                        'made_flush': responder_made_flush,\n",
    "                                        'made_straight': responder_made_straight,\n",
    "                                        'made_full_house': responder_made_full,\n",
    "                                    }\n",
    "                                )\n",
    "                                responders_recorded.add(player)\n",
    "                    if amount > 0:\n",
    "                        total_pot += amount\n",
    "                if round_no != 2:\n",
    "                    current_event = None\n",
    "\n",
    "    if cache_path:\n",
    "        cache_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        with cache_path.open('w', encoding='utf-8') as fh:\n",
    "            json.dump(events, fh, ensure_ascii=False, indent=2)\n",
    "\n",
    "    return events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3884660-308f-492d-bfee-e0939835a636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "RAW_BUCKET_BOUNDS = [\n",
    "    (0.00, 0.25),\n",
    "    (0.25, 0.40),\n",
    "    (0.40, 0.60),\n",
    "    (0.60, 0.80),\n",
    "    (0.80, 1.00),\n",
    "    (1.00, 1.25),\n",
    "    (1.25, float(\"inf\")),\n",
    "]\n",
    "\n",
    "def _bucket_label(low: float, high: float) -> str:\n",
    "    if high == float(\"inf\"):\n",
    "        return f\">={low:.2f}\"\n",
    "    return f\"[{low:.2f}, {high:.2f})\"\n",
    "\n",
    "BUCKETS = [(low, high, _bucket_label(low, high)) for (low, high) in RAW_BUCKET_BOUNDS]\n",
    "del _bucket_label\n",
    "\n",
    "PRIMARY_GROUPS = {cat: [cat] for cat in BASE_PRIMARY_CATEGORIES}\n",
    "DRAW_FLAGS = DEFAULT_DRAW_FLAGS.copy()\n",
    "\n",
    "# Set to True to rebuild the cache after changing parsing logic.\n",
    "FORCE_RELOAD = True\n",
    "\n",
    "TURN_CACHE_PATH = PROJECT_ROOT / \"analysis/cache/turn_events.json\"\n",
    "TURN_FORCE_RELOAD = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9a54fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = load_donk_events(DB_PATH, cache_path=CACHE_PATH, force=FORCE_RELOAD)\n",
    "print(f\"Loaded {len(events)} donk-bet events.\")\n",
    "available_categories = available_primary_categories(events)\n",
    "print(\"Observed primary categories:\", \", \".join(available_categories))\n",
    "\n",
    "try:\n",
    "    turn_events = load_turn_events_turn(DB_PATH, cache_path=TURN_CACHE_PATH, force=TURN_FORCE_RELOAD)\n",
    "    turn_responses = turn_response_events_turn(turn_events)\n",
    "except FileNotFoundError:\n",
    "    turn_events = []\n",
    "    turn_responses = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217f63ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "DEFAULT_DROP_COLUMNS = {\"Range\", \"Made Flush\", \"Made Straight\"}\n",
    "\n",
    "GROUPED_PRIMARY_ORDER = [\n",
    "    (\"Events\", None),\n",
    "    (\"Air\", [\"Air\"]),\n",
    "    (\"Weak Pair\", [\"Underpair\", \"Bottom Pair\", \"Middle Pair\"]),\n",
    "    (\"Top Pair\", [\"Top Pair\"]),\n",
    "    (\"Overpair\", [\"Overpair\"]),\n",
    "    (\"Two Pair\", [\"Two Pair\"]),\n",
    "    (\"Trips/Set\", [\"Trips/Set\"]),\n",
    "    (\"Monster\", [\"Straight\", \"Flush\", \"Full House\", \"Quads\"]),\n",
    "    (\"Draw\", [\"Flush Draw\", \"OESD/DG\"]),\n",
    "]\n",
    "\n",
    "RESPONSE_GROUP_ORDER = [\n",
    "    (\"Events\", None),\n",
    "    (\"Fold\", [\"Fold\"]),\n",
    "    (\"Call\", [\"Call\"]),\n",
    "    (\"Raise\", [\"Raise\"]),\n",
    "    (\"Continue\", [\"Call\", \"Raise\"]),\n",
    "]\n",
    "\n",
    "def _gradient_cmap(base_color: str) -> LinearSegmentedColormap:\n",
    "    name = f'gradient_{base_color.strip(\"#\")}'\n",
    "    return LinearSegmentedColormap.from_list(name, ['#ffffff', base_color])\n",
    "\n",
    "def _summary_records_to_df(records, drop_columns=None):\n",
    "    if not records:\n",
    "        return pd.DataFrame()\n",
    "    df = pd.DataFrame(records)\n",
    "    drop_columns = drop_columns or set()\n",
    "    for col in drop_columns:\n",
    "        if col in df.columns:\n",
    "            df = df.drop(columns=[col])\n",
    "    df = df.set_index(\"Bucket\").T\n",
    "    df = df.apply(pd.to_numeric, errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "def _style_heatmap(df, title, base_color=\"#1f77b4\", fmt=\"{:.1f}\", special_columns=None):\n",
    "    if df.empty:\n",
    "        return None\n",
    "    data_index = df.index.difference([\"Events\"])\n",
    "    styled = df.style.format(fmt)\n",
    "    if not data_index.empty:\n",
    "        styled = styled.background_gradient(\n",
    "            cmap=_gradient_cmap(base_color),\n",
    "            axis=None,\n",
    "            subset=pd.IndexSlice[data_index, :]\n",
    "        )\n",
    "    if special_columns:\n",
    "        first = special_columns[0]\n",
    "        if first in df.columns:\n",
    "            col_idx = df.columns.get_loc(first)\n",
    "            styles = [\n",
    "                {\n",
    "                    'selector': f'th.col_heading.level0.col{col_idx}',\n",
    "                    'props': [('border-left', '2px solid #64748b')]\n",
    "                },\n",
    "                {\n",
    "                    'selector': f'td.col{col_idx}',\n",
    "                    'props': [('border-left', '2px solid #64748b')]\n",
    "                },\n",
    "            ]\n",
    "            styled = styled.set_table_styles(styles, overwrite=False)\n",
    "    return styled.set_caption(title)\n",
    "\n",
    "def _aggregate_grouped(df, group_order):\n",
    "    rows = []\n",
    "    for label, members in group_order:\n",
    "        if members is None:\n",
    "            if \"Events\" in df.index:\n",
    "                rows.append((label, df.loc[\"Events\"]))\n",
    "            continue\n",
    "        available = [member for member in members if member in df.index]\n",
    "        if not available:\n",
    "            continue\n",
    "        rows.append((label, df.loc[available].sum()))\n",
    "    if not rows:\n",
    "        return pd.DataFrame()\n",
    "    data = pd.DataFrame([series for _, series in rows], index=[label for label, _ in rows])\n",
    "    return data\n",
    "\n",
    "def display_heatmap_tables(summary_records, title, *, base_color=\"#1f77b4\", group_color=\"#2ca25f\", special_rows=None):\n",
    "    records = list(summary_records)\n",
    "    special_columns = []\n",
    "    if special_rows:\n",
    "        records.extend(special_rows)\n",
    "        special_columns = [row['Bucket'] for row in special_rows if row.get('Bucket')]\n",
    "    base_df = _summary_records_to_df(records, DEFAULT_DROP_COLUMNS)\n",
    "    styled = _style_heatmap(base_df, title, base_color=base_color, special_columns=special_columns)\n",
    "    if styled is not None:\n",
    "        display(styled)\n",
    "    grouped_df = _aggregate_grouped(base_df, GROUPED_PRIMARY_ORDER)\n",
    "    styled_grouped = _style_heatmap(grouped_df, f\"{title} (Grouped)\", base_color=group_color, special_columns=special_columns)\n",
    "    if styled_grouped is not None:\n",
    "        display(styled_grouped)\n",
    "\n",
    "def summarize_responses_df(responses_df, buckets):\n",
    "    summary = []\n",
    "    for low, high, label in buckets:\n",
    "        subset = responses_df[(responses_df['ratio'] >= low) & (responses_df['ratio'] < high)]\n",
    "        if subset.empty:\n",
    "            summary.append({\n",
    "                'Bucket': label,\n",
    "                'Events': 0,\n",
    "                'Fold': 0.0,\n",
    "                'Call': 0.0,\n",
    "                'Raise': 0.0,\n",
    "                'Continue': 0.0,\n",
    "            })\n",
    "            continue\n",
    "        events_count = len(subset)\n",
    "        response_counts = subset['response'].value_counts()\n",
    "        continue_count = int(response_counts.get('Call', 0) + response_counts.get('Raise', 0))\n",
    "        summary.append({\n",
    "            'Bucket': label,\n",
    "            'Events': events_count,\n",
    "            'Fold': response_counts.get('Fold', 0) / events_count * 100,\n",
    "            'Call': response_counts.get('Call', 0) / events_count * 100,\n",
    "            'Raise': response_counts.get('Raise', 0) / events_count * 100,\n",
    "            'Continue': continue_count / events_count * 100,\n",
    "        })\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c401766",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df' not in locals():\n",
    "    df = events_to_dataframe(events)\n",
    "\n",
    "df = df.copy()\n",
    "bucket_edges = [bucket[0] for bucket in BUCKETS] + [BUCKETS[-1][1]]\n",
    "bucket_labels = [bucket[2] for bucket in BUCKETS]\n",
    "df['bucket'] = pd.cut(df['ratio'], bins=bucket_edges, labels=bucket_labels, right=False, include_lowest=True)\n",
    "\n",
    "def _filtered_primary_groups(subset_records):\n",
    "    available = {event['primary'] for event in subset_records}\n",
    "    groups = {}\n",
    "    for name, members in PRIMARY_GROUPS.items():\n",
    "        members_in_subset = [cat for cat in members if cat in available]\n",
    "        if members_in_subset:\n",
    "            groups[name] = members_in_subset\n",
    "    if not groups:\n",
    "        for cat in sorted(available):\n",
    "            groups[cat] = [cat]\n",
    "    return groups\n",
    "\n",
    "def _build_special_rows(subset_records):\n",
    "    specials = []\n",
    "    special_specs = [\n",
    "        (\"All-In\", lambda event: event.get(\"is_all_in\")),\n",
    "        (\"1 BB\", lambda event: event.get(\"is_one_bb\")),\n",
    "    ]\n",
    "    for label, predicate in special_specs:\n",
    "        filtered = [event for event in subset_records if predicate(event)]\n",
    "        if not filtered:\n",
    "            continue\n",
    "        groups = _filtered_primary_groups(filtered)\n",
    "        specials.extend(\n",
    "            summarize_events(\n",
    "                filtered,\n",
    "                [(0.0, float(\"inf\"), label)],\n",
    "                groups,\n",
    "                DRAW_FLAGS,\n",
    "            )\n",
    "        )\n",
    "    return specials\n",
    "\n",
    "def display_heatmap_for_mask(mask, title, base_color='#1f77b4', group_color='#2ca25f'):\n",
    "    subset = df.loc[mask]\n",
    "    subset_records = subset.to_dict('records')\n",
    "    if not subset_records:\n",
    "        display(pd.DataFrame({'Bucket': bucket_labels, 'Message': 'No events'}))\n",
    "        return\n",
    "    groups = _filtered_primary_groups(subset_records)\n",
    "    summary_subset = summarize_events(subset_records, BUCKETS, groups, DRAW_FLAGS)\n",
    "    special_rows = _build_special_rows(subset_records)\n",
    "    display_heatmap_tables(\n",
    "        summary_subset,\n",
    "        title,\n",
    "        base_color=base_color,\n",
    "        group_color=group_color,\n",
    "        special_rows=special_rows,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbet-helper-heatmap",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_records = summarize_events(events, BUCKETS, PRIMARY_GROUPS, DRAW_FLAGS)\n",
    "special_rows = _build_special_rows(events)\n",
    "display_heatmap_tables(summary_records, \"All Donk Bets\", special_rows=special_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbet-ip-oop",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_heatmap_for_mask(df['in_position'], 'Donk Bets In Position', base_color='#1f77b4', group_color='#2ca25f')\n",
    "display_heatmap_for_mask(~df['in_position'], 'Donk Bets Out of Position', base_color='#d95f02', group_color='#7570b3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbet-flop-players",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def flop_group(count):\n",
    "    if count <= 2:\n",
    "        return '2 Players'\n",
    "    if count == 3:\n",
    "        return '3 Players'\n",
    "    return '4+ Players'\n",
    "\n",
    "df['flop_group'] = df['flop_players'].apply(flop_group)\n",
    "\n",
    "donk_group_titles = [\n",
    "    ('2 Players', 'Donk Bets (2 Players)'),\n",
    "    ('3 Players', 'Donk Bets (3 Players)'),\n",
    "    ('4+ Players', 'Donk Bets (4 Players)'),\n",
    "]\n",
    "\n",
    "for group_key, title in donk_group_titles:\n",
    "    mask = df['flop_group'] == group_key\n",
    "    if mask.any():\n",
    "        display_heatmap_for_mask(mask, title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80082f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response_rows = response_events(events)\n",
    "responses_df = pd.DataFrame(response_rows)\n",
    "\n",
    "def _prepare_response_table(records):\n",
    "    if not records:\n",
    "        return pd.DataFrame()\n",
    "    df = pd.DataFrame(records)\n",
    "    if 'Bucket' not in df.columns:\n",
    "        return pd.DataFrame()\n",
    "    df = df.set_index('Bucket').T.apply(pd.to_numeric, errors='coerce')\n",
    "    row_order = ['Events', 'Fold', 'Call', 'Raise', 'Continue']\n",
    "    ordered = [row for row in row_order if row in df.index]\n",
    "    extras = [row for row in df.index if row not in row_order]\n",
    "    if ordered or extras:\n",
    "        df = df.loc[ordered + extras]\n",
    "    return df\n",
    "\n",
    "def _response_summary(subset_df):\n",
    "    if subset_df is None or subset_df.empty:\n",
    "        return {'Events': 0, 'Fold': 0.0, 'Call': 0.0, 'Raise': 0.0, 'Continue': 0.0}\n",
    "    events_count = len(subset_df)\n",
    "    response_counts = subset_df['response'].value_counts()\n",
    "    continue_count = int(response_counts.get('Call', 0) + response_counts.get('Raise', 0))\n",
    "    return {\n",
    "        'Events': events_count,\n",
    "        'Fold': response_counts.get('Fold', 0) / events_count * 100,\n",
    "        'Call': response_counts.get('Call', 0) / events_count * 100,\n",
    "        'Raise': response_counts.get('Raise', 0) / events_count * 100,\n",
    "        'Continue': continue_count / events_count * 100,\n",
    "    }\n",
    "\n",
    "def _compute_special_columns(source_df):\n",
    "    specials = {}\n",
    "    if source_df is None:\n",
    "        return specials\n",
    "    if 'is_all_in_cbet' in source_df.columns:\n",
    "        specials['All-In'] = _response_summary(source_df[source_df['is_all_in_cbet']])\n",
    "    if 'is_one_bb_cbet' in source_df.columns:\n",
    "        specials['1 BB'] = _response_summary(source_df[source_df['is_one_bb_cbet']])\n",
    "    return specials\n",
    "\n",
    "def _style_response_table(df, title, base_color: str = '#6baed6'):\n",
    "    if df.empty:\n",
    "        return None\n",
    "    percent_rows = [row for row in ['Fold', 'Call', 'Raise', 'Continue'] if row in df.index]\n",
    "    styled = df.style\n",
    "    if 'Events' in df.index:\n",
    "        styled = styled.format('{:.0f}', subset=pd.IndexSlice[['Events'], :])\n",
    "    if percent_rows:\n",
    "        styled = styled.format('{:.1f}%', subset=pd.IndexSlice[percent_rows, :])\n",
    "        styled = styled.background_gradient(\n",
    "            cmap=_gradient_cmap(base_color),\n",
    "            axis=None,\n",
    "            subset=pd.IndexSlice[percent_rows, :]\n",
    "        )\n",
    "    special_cols = [col for col in ['All-In', '1 BB'] if col in df.columns]\n",
    "    if special_cols:\n",
    "        first = special_cols[0]\n",
    "        idx = df.columns.get_loc(first)\n",
    "        styled = styled.set_table_styles([\n",
    "            {'selector': f'th.col_heading.level0.col{idx}', 'props': [('border-left', '2px solid #64748b')]},\n",
    "            {'selector': f'td.col{idx}', 'props': [('border-left', '2px solid #64748b')]},\n",
    "        ], overwrite=False)\n",
    "    return styled.set_caption(title)\n",
    "\n",
    "def display_response_tables(summary_records, title, base_color='#6baed6', source_df=None):\n",
    "    df = _prepare_response_table(summary_records)\n",
    "    if df.empty:\n",
    "        display(pd.DataFrame({'Bucket': bucket_labels, 'Message': 'No events'}))\n",
    "        return\n",
    "    specials = _compute_special_columns(source_df)\n",
    "    if specials:\n",
    "        for col_name, values in specials.items():\n",
    "            for row in df.index:\n",
    "                df.loc[row, col_name] = values.get(row, 0.0)\n",
    "    styled = _style_response_table(df, title, base_color=base_color)\n",
    "    if styled is not None:\n",
    "        display(styled)\n",
    "\n",
    "def display_response_for_mask(mask, title, base_color='#6baed6'):\n",
    "    if responses_df.empty:\n",
    "        display(pd.DataFrame({'Bucket': bucket_labels, 'Message': 'No events'}))\n",
    "        return\n",
    "    subset = responses_df.loc[mask]\n",
    "    if subset.empty:\n",
    "        display(pd.DataFrame({'Bucket': bucket_labels, 'Message': 'No events'}))\n",
    "        return\n",
    "    summary_subset = summarize_responses_df(subset, BUCKETS)\n",
    "    display_response_tables(summary_subset, title, base_color=base_color, source_df=subset)\n",
    "\n",
    "def _prepare_turn_response_records(turn_events, turn_responses, line_type, response_type):\n",
    "    records = []\n",
    "    for response in turn_responses:\n",
    "        if response.get('line_type') != line_type:\n",
    "            continue\n",
    "        if response.get('response') != response_type:\n",
    "            continue\n",
    "        primary = response.get('responder_primary')\n",
    "        if not primary:\n",
    "            continue\n",
    "        records.append({\n",
    "            'ratio': float(response.get('ratio', 0.0)),\n",
    "            'primary': primary,\n",
    "            'has_flush_draw': bool(response.get('responder_has_flush_draw')),\n",
    "            'has_oesd_dg': bool(response.get('responder_has_oesd_dg')),\n",
    "            'made_flush': bool(response.get('responder_made_flush')),\n",
    "            'made_straight': bool(response.get('responder_made_straight')),\n",
    "        })\n",
    "    return records\n",
    "\n",
    "def _summarize_response_records(records, buckets):\n",
    "    summary = []\n",
    "    for low, high, label in buckets:\n",
    "        bucket_records = [rec for rec in records if low <= rec['ratio'] < high]\n",
    "        if not bucket_records:\n",
    "            row = {'Bucket': label, 'Events': 0}\n",
    "            for group_name in PRIMARY_GROUPS:\n",
    "                row[group_name] = 0.0\n",
    "            for draw_name in DRAW_FLAGS:\n",
    "                row[draw_name] = 0.0\n",
    "            summary.append(row)\n",
    "            continue\n",
    "        total = len(bucket_records)\n",
    "        row = {'Bucket': label, 'Events': total}\n",
    "        for group_name, members in PRIMARY_GROUPS.items():\n",
    "            row[group_name] = sum(rec['primary'] in members for rec in bucket_records) / total * 100\n",
    "        for draw_name, field in DRAW_FLAGS.items():\n",
    "            row[draw_name] = sum(bool(rec.get(field)) for rec in bucket_records) / total * 100\n",
    "        summary.append(row)\n",
    "    return summary\n",
    "\n",
    "def display_turn_response_holdings(turn_events, turn_responses, line_type, response_type, title, *, base_color='#1f77b4', group_color='#2ca25f'):\n",
    "    records = _prepare_turn_response_records(turn_events, turn_responses, line_type, response_type)\n",
    "    if not records:\n",
    "        print(f\"No {response_type.lower()} responses recorded for {line_type.lower()} line.\")\n",
    "        return\n",
    "    summary = _summarize_response_records(records, TURN_BUCKETS_TURN)\n",
    "    display_heatmap_tables(summary, title, base_color=base_color, group_color=group_color)\n",
    "\n",
    "def _villain_response_metrics(subset_df):\n",
    "    events = len(subset_df)\n",
    "    if events == 0:\n",
    "        return {\n",
    "            'Events': 0,\n",
    "            'Fold%': 0.0,\n",
    "            'Call%': 0.0,\n",
    "            'Raise%': 0.0,\n",
    "            'Continue%': 0.0,\n",
    "            'Avg Call Amount': 0.0,\n",
    "            'Avg Raise Amount': 0.0,\n",
    "            'Expected Continue Amount': 0.0,\n",
    "        }\n",
    "    fold_pct = subset_df['response'].eq('Fold').mean() * 100\n",
    "    call_mask = subset_df['response'].eq('Call')\n",
    "    raise_mask = subset_df['response'].eq('Raise')\n",
    "    call_pct = call_mask.mean() * 100\n",
    "    raise_pct = raise_mask.mean() * 100\n",
    "    continue_pct = call_pct + raise_pct\n",
    "    avg_call_amt = subset_df.loc[call_mask, 'response_amount'].mean() if call_mask.any() else 0.0\n",
    "    avg_raise_amt = subset_df.loc[raise_mask, 'response_amount'].mean() if raise_mask.any() else 0.0\n",
    "    expected_continue = (call_pct / 100) * (avg_call_amt or 0.0) + (raise_pct / 100) * (avg_raise_amt or 0.0)\n",
    "    return {\n",
    "        'Events': float(events),\n",
    "        'Fold%': fold_pct,\n",
    "        'Call%': call_pct,\n",
    "        'Raise%': raise_pct,\n",
    "        'Continue%': continue_pct,\n",
    "        'Avg Call Amount': avg_call_amt or 0.0,\n",
    "        'Avg Raise Amount': avg_raise_amt or 0.0,\n",
    "        'Expected Continue Amount': expected_continue,\n",
    "    }\n",
    "\n",
    "def summarize_response_ev(responses_df, buckets):\n",
    "    summary = []\n",
    "    for low, high, label in buckets:\n",
    "        subset = responses_df[(responses_df['ratio'] >= low) & (responses_df['ratio'] < high)]\n",
    "        metrics = _villain_response_metrics(subset)\n",
    "        metrics['Bucket'] = label\n",
    "        summary.append(metrics)\n",
    "    return summary\n",
    "\n",
    "def display_response_ev_table(responses_df, title, base_color='#6baed6'):\n",
    "    records = summarize_response_ev(responses_df, TURN_BUCKETS)\n",
    "    df = pd.DataFrame(records)\n",
    "    if df.empty:\n",
    "        display(pd.DataFrame({'Bucket': [bucket[2] for bucket in TURN_BUCKETS], 'Message': 'No events'}))\n",
    "        return\n",
    "    df = df.set_index('Bucket').T.apply(pd.to_numeric, errors='coerce')\n",
    "    styled = (\n",
    "        df.style\n",
    "        .format('{:.0f}', subset=pd.IndexSlice[['Events'], :])\n",
    "        .format('{:.1f}%', subset=pd.IndexSlice[['Fold%', 'Call%', 'Raise%', 'Continue%'], :])\n",
    "        .format('{:.2f}', subset=pd.IndexSlice[['Avg Call Amount', 'Avg Raise Amount', 'Expected Continue Amount'], :])\n",
    "        .background_gradient(cmap=_gradient_cmap(base_color), axis=None, subset=pd.IndexSlice[['Fold%', 'Call%', 'Raise%', 'Continue%'], :])\n",
    "        .set_caption(title)\n",
    "    )\n",
    "    display(styled)\n",
    "\n",
    "if responses_df.empty:\n",
    "    print(\"No donk bet response events available.\")\n",
    "else:\n",
    "    responses_df['bucket'] = pd.cut(\n",
    "        responses_df['ratio'],\n",
    "        bins=bucket_edges,\n",
    "        labels=bucket_labels,\n",
    "        right=False,\n",
    "        include_lowest=True,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524a6c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _filter_standard_donk_events(events_df):\n",
    "    if events_df is None or events_df.empty:\n",
    "        return events_df.iloc[0:0].copy()\n",
    "    mask = pd.Series(True, index=events_df.index)\n",
    "    if 'is_all_in' in events_df.columns:\n",
    "        mask &= ~events_df['is_all_in']\n",
    "    if 'is_one_bb' in events_df.columns:\n",
    "        mask &= ~events_df['is_one_bb']\n",
    "    return events_df.loc[mask].copy()\n",
    "\n",
    "\n",
    "def _filter_standard_donk_responses(responses_df):\n",
    "    if responses_df is None or responses_df.empty:\n",
    "        return responses_df.iloc[0:0].copy()\n",
    "    mask = pd.Series(True, index=responses_df.index)\n",
    "    if 'is_all_in_cbet' in responses_df.columns:\n",
    "        mask &= ~responses_df['is_all_in_cbet']\n",
    "    if 'is_one_bb_cbet' in responses_df.columns:\n",
    "        mask &= ~responses_df['is_one_bb_cbet']\n",
    "    return responses_df.loc[mask].copy()\n",
    "\n",
    "\n",
    "def _safe_mean(series):\n",
    "    if series is None or len(series) == 0:\n",
    "        return 0.0\n",
    "    cleaned = series.dropna()\n",
    "    if cleaned.empty:\n",
    "        return 0.0\n",
    "    value = cleaned.mean()\n",
    "    return float(value) if pd.notna(value) else 0.0\n",
    "\n",
    "\n",
    "def _prepare_donk_event_metrics(events_subset, responses_subset, *, exclude_special=True):\n",
    "    if events_subset is None or events_subset.empty:\n",
    "        return pd.DataFrame()\n",
    "    events_work = events_subset.copy()\n",
    "    responses_work = responses_subset.copy()\n",
    "    if exclude_special:\n",
    "        events_work = _filter_standard_donk_events(events_work)\n",
    "        responses_work = _filter_standard_donk_responses(responses_work)\n",
    "    if events_work.empty:\n",
    "        return pd.DataFrame()\n",
    "    events_work = events_work.rename(columns={'player': 'bettor'})\n",
    "    base_cols = [\n",
    "        'hand_number',\n",
    "        'bettor',\n",
    "        'ratio',\n",
    "        'bucket',\n",
    "        'bet_amount',\n",
    "        'bet_amount_bb',\n",
    "        'big_blind',\n",
    "    ]\n",
    "    missing = [col for col in base_cols if col not in events_work.columns]\n",
    "    if missing:\n",
    "        raise KeyError(f\"Missing columns in events dataframe: {', '.join(missing)}\")\n",
    "    events_work = events_work[base_cols].copy()\n",
    "    if not responses_work.empty:\n",
    "        allowed = set(zip(events_work['hand_number'], events_work['bettor']))\n",
    "        responses_work = responses_work[\n",
    "            responses_work.apply(lambda row: (row['hand_number'], row['bettor']) in allowed, axis=1)\n",
    "        ]\n",
    "    if responses_work.empty:\n",
    "        grouped = pd.DataFrame(\n",
    "            columns=[\n",
    "                'hand_number',\n",
    "                'bettor',\n",
    "                'continue_amount',\n",
    "                'call_amount',\n",
    "                'raise_amount',\n",
    "                'call_flag',\n",
    "                'raise_flag',\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        prepped = responses_work.copy()\n",
    "        prepped['continue_amount'] = np.where(\n",
    "            prepped['response'].isin(['Call', 'Raise']),\n",
    "            prepped['response_amount'],\n",
    "            0.0,\n",
    "        )\n",
    "        prepped['call_amount'] = np.where(\n",
    "            prepped['response'] == 'Call',\n",
    "            prepped['response_amount'],\n",
    "            0.0,\n",
    "        )\n",
    "        prepped['raise_amount'] = np.where(\n",
    "            prepped['response'] == 'Raise',\n",
    "            prepped['response_amount'],\n",
    "            0.0,\n",
    "        )\n",
    "        prepped['call_flag'] = (prepped['response'] == 'Call').astype(int)\n",
    "        prepped['raise_flag'] = (prepped['response'] == 'Raise').astype(int)\n",
    "        grouped = (\n",
    "            prepped.groupby(['hand_number', 'bettor'], as_index=False)\n",
    "            .agg({\n",
    "                'continue_amount': 'sum',\n",
    "                'call_amount': 'sum',\n",
    "                'raise_amount': 'sum',\n",
    "                'call_flag': 'max',\n",
    "                'raise_flag': 'max',\n",
    "            })\n",
    "        )\n",
    "    metrics = events_work.merge(grouped, on=['hand_number', 'bettor'], how='left')\n",
    "    for col in ['continue_amount', 'call_amount', 'raise_amount']:\n",
    "        metrics[col] = metrics[col].fillna(0.0)\n",
    "    for col in ['call_flag', 'raise_flag']:\n",
    "        metrics[col] = metrics[col].fillna(0).astype(int)\n",
    "    metrics['continue_flag'] = metrics['continue_amount'] > 0\n",
    "    metrics['call_only_flag'] = (metrics['call_flag'] > 0) & (metrics['raise_flag'] == 0)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        metrics['pot_before'] = np.where(\n",
    "            metrics['ratio'] > 0,\n",
    "            metrics['bet_amount'] / metrics['ratio'],\n",
    "            np.nan,\n",
    "        )\n",
    "        metrics['bet_ratio_pct'] = metrics['ratio'].astype(float) * 100.0\n",
    "        metrics['raise_ratio_pct'] = np.where(\n",
    "            (metrics['raise_flag'] > 0) & (metrics['pot_before'] > 0),\n",
    "            (metrics['raise_amount'] / metrics['pot_before']) * 100.0,\n",
    "            np.nan,\n",
    "        )\n",
    "        metrics['breakeven_fold_pct'] = np.where(\n",
    "            (metrics['bet_amount'] + metrics['pot_before']) > 0,\n",
    "            metrics['bet_amount'] / (metrics['bet_amount'] + metrics['pot_before']) * 100,\n",
    "            np.nan,\n",
    "        )\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def _compute_donk_bucket_metrics(metrics_df, buckets=BUCKETS):\n",
    "    results = []\n",
    "    if metrics_df is None or metrics_df.empty:\n",
    "        for _, _, label in buckets:\n",
    "            results.append({'Bucket': label, 'Events': 0.0})\n",
    "        return results\n",
    "    for low, high, label in buckets:\n",
    "        bucket_mask = (metrics_df['ratio'] >= low) & (metrics_df['ratio'] < high)\n",
    "        bucket_events = metrics_df.loc[bucket_mask]\n",
    "        total = len(bucket_events)\n",
    "        if total == 0:\n",
    "            results.append({'Bucket': label, 'Events': 0.0})\n",
    "            continue\n",
    "        continue_events = int(bucket_events['continue_flag'].sum())\n",
    "        raise_events = int(bucket_events['raise_flag'].sum())\n",
    "        call_only_events = int(bucket_events['call_only_flag'].sum())\n",
    "        continue_pct = continue_events / total * 100\n",
    "        raise_pct = raise_events / total * 100\n",
    "        call_only_pct = call_only_events / total * 100\n",
    "        fold_pct = 100.0 - continue_pct\n",
    "        avg_ratio_pct = _safe_mean(bucket_events['bet_ratio_pct'])\n",
    "        raise_mask = bucket_events['raise_flag'] > 0\n",
    "        avg_raise_ratio_pct = _safe_mean(bucket_events.loc[raise_mask, 'raise_ratio_pct'])\n",
    "        avg_breakeven = _safe_mean(bucket_events['breakeven_fold_pct'])\n",
    "        expected_call_contrib_pct = (call_only_pct * avg_ratio_pct) / 100.0 if not np.isnan(avg_ratio_pct) else 0.0\n",
    "        expected_raise_contrib_pct = (raise_pct * avg_raise_ratio_pct) / 100.0 if not np.isnan(avg_raise_ratio_pct) else 0.0\n",
    "        total_contrib_pct = expected_call_contrib_pct + expected_raise_contrib_pct\n",
    "        row = {\n",
    "            'Bucket': label,\n",
    "            'Events': float(total),\n",
    "            'Fold%': fold_pct,\n",
    "            'Continue%': continue_pct,\n",
    "            'Call-Only%': call_only_pct,\n",
    "            'Raise%': raise_pct,\n",
    "            'Avg Size (Pot%)': avg_ratio_pct,\n",
    "            'Avg Raise Size (Pot%)': avg_raise_ratio_pct,\n",
    "            'Expected Call Contribution (Pot%)': expected_call_contrib_pct,\n",
    "            'Expected Raise Contribution (Pot%)': expected_raise_contrib_pct,\n",
    "            'Raise Contribution Total (Pot%)': total_contrib_pct,\n",
    "            'Breakeven Fold%': avg_breakeven,\n",
    "        }\n",
    "        row['Fold Surplus'] = row['Fold%'] - row['Breakeven Fold%']\n",
    "        results.append(row)\n",
    "    return results\n",
    "\n",
    "\n",
    "VALUE_COLUMNS_CBET = [\n",
    "    'Bucket',\n",
    "    'Events',\n",
    "    'Continue%',\n",
    "    'Call-Only%',\n",
    "    'Raise%',\n",
    "    'Avg Size (Pot%)',\n",
    "    'Avg Raise Size (Pot%)',\n",
    "    'Expected Call Contribution (Pot%)',\n",
    "    'Expected Raise Contribution (Pot%)',\n",
    "    'Raise Contribution Total (Pot%)',\n",
    "]\n",
    "\n",
    "\n",
    "PRESSURE_COLUMNS_CBET = [\n",
    "    'Bucket',\n",
    "    'Events',\n",
    "    'Fold%',\n",
    "    'Avg Size (Pot%)',\n",
    "    'Breakeven Fold%',\n",
    "    'Fold Surplus',\n",
    "]\n",
    "\n",
    "\n",
    "_FOLD_SURPLUS_CMAP = LinearSegmentedColormap.from_list(\n",
    "    'fold_surplus_cmp_flop', ['#b91c1c', '#ffffff', '#15803d']\n",
    ")\n",
    "\n",
    "\n",
    "def _style_donk_value_table(table_df, title):\n",
    "    if table_df.empty:\n",
    "        return None\n",
    "    df = table_df.set_index('Bucket').T\n",
    "    percent_rows = [row for row in df.index if row != 'Events']\n",
    "    styled = df.style\n",
    "    if 'Events' in df.index:\n",
    "        styled = styled.format('{:.0f}', subset=pd.IndexSlice[['Events'], :])\n",
    "    if percent_rows:\n",
    "        styled = styled.format('{:.1f}%', subset=pd.IndexSlice[percent_rows, :])\n",
    "        contribution_rows = [row for row in percent_rows if 'Contribution' in row]\n",
    "        size_rows = [row for row in percent_rows if 'Size' in row]\n",
    "        pct_rows_other = [row for row in percent_rows if row not in contribution_rows + size_rows]\n",
    "        if pct_rows_other:\n",
    "            styled = styled.background_gradient(\n",
    "                cmap='YlOrRd',\n",
    "                axis=None,\n",
    "                subset=pd.IndexSlice[pct_rows_other, :],\n",
    "            )\n",
    "        if size_rows:\n",
    "            styled = styled.background_gradient(\n",
    "                cmap='BuGn',\n",
    "                axis=None,\n",
    "                subset=pd.IndexSlice[size_rows, :],\n",
    "            )\n",
    "        if contribution_rows:\n",
    "            styled = styled.background_gradient(\n",
    "                cmap='PuBu',\n",
    "                axis=None,\n",
    "                subset=pd.IndexSlice[contribution_rows, :],\n",
    "            )\n",
    "    return styled.set_caption(title)\n",
    "\n",
    "\n",
    "def _style_donk_pressure_table(table_df, title):\n",
    "    if table_df.empty:\n",
    "        return None\n",
    "    df = table_df.set_index('Bucket').T\n",
    "    desired_order = ['Events', 'Fold%', 'Avg Size (Pot%)', 'Breakeven Fold%', 'Fold Surplus']\n",
    "    existing_order = [row for row in desired_order if row in df.index]\n",
    "    df = df.loc[existing_order]\n",
    "    styled = df.style\n",
    "    if 'Events' in df.index:\n",
    "        styled = styled.format('{:.0f}', subset=pd.IndexSlice[['Events'], :])\n",
    "    percent_rows = [row for row in df.index if row != 'Events']\n",
    "    if percent_rows:\n",
    "        styled = styled.format('{:.1f}%', subset=pd.IndexSlice[percent_rows, :])\n",
    "    if 'Fold%' in df.index:\n",
    "        styled = styled.background_gradient(\n",
    "            cmap='YlOrRd',\n",
    "            axis=None,\n",
    "            subset=pd.IndexSlice[['Fold%'], :],\n",
    "        )\n",
    "    if 'Avg Size (Pot%)' in df.index:\n",
    "        styled = styled.background_gradient(\n",
    "            cmap='BuGn',\n",
    "            axis=None,\n",
    "            subset=pd.IndexSlice[['Avg Size (Pot%)'], :],\n",
    "        )\n",
    "    if 'Fold Surplus' in df.index:\n",
    "        fold_values = df.loc['Fold Surplus'].dropna().astype(float)\n",
    "        if not fold_values.empty:\n",
    "            max_abs = max(abs(fold_values.min()), abs(fold_values.max()))\n",
    "            if max_abs == 0:\n",
    "                max_abs = 1.0\n",
    "            styled = styled.background_gradient(\n",
    "                cmap=_FOLD_SURPLUS_CMAP,\n",
    "                axis=None,\n",
    "                subset=pd.IndexSlice[['Fold Surplus'], :],\n",
    "                vmin=-max_abs,\n",
    "                vmax=max_abs,\n",
    "            )\n",
    "    return styled.set_caption(title)\n",
    "\n",
    "\n",
    "def _display_donk_event_tables(metrics_df, title_prefix):\n",
    "    if metrics_df is None or metrics_df.empty:\n",
    "        print(f'No events available for {title_prefix}.')\n",
    "        return\n",
    "    records = _compute_donk_bucket_metrics(metrics_df)\n",
    "    if not records:\n",
    "        print(f'No bucketed metrics available for {title_prefix}.')\n",
    "        return\n",
    "    metrics_table = pd.DataFrame(records)\n",
    "    value_columns = [col for col in VALUE_COLUMNS_CBET if col in metrics_table.columns]\n",
    "    pressure_columns = [col for col in PRESSURE_COLUMNS_CBET if col in metrics_table.columns]\n",
    "    value_table = metrics_table[value_columns]\n",
    "    pressure_table = metrics_table[pressure_columns]\n",
    "    value_styled = _style_donk_value_table(value_table, f\"{title_prefix} - Value Profile\")\n",
    "    if value_styled is not None:\n",
    "        display(value_styled)\n",
    "    pressure_styled = _style_donk_pressure_table(pressure_table, f\"{title_prefix} - Fold Pressure\")\n",
    "    if pressure_styled is not None:\n",
    "        display(pressure_styled)\n",
    "\n",
    "\n",
    "def display_donk_event_ev_tables(title_prefix='Flop Donk Bet Event Outcomes', *, exclude_special=True):\n",
    "    if df.empty or responses_df.empty:\n",
    "        print('No donk bet events or responses available for event-level contribution tables.')\n",
    "        return\n",
    "    base_metrics = _prepare_donk_event_metrics(df, responses_df, exclude_special=exclude_special)\n",
    "    if base_metrics.empty:\n",
    "        print('No donk bet events remain after filtering special cases.')\n",
    "        return\n",
    "    subsets = [\n",
    "        (base_metrics, f\"{title_prefix} (Overall)\"),\n",
    "        (\n",
    "            _prepare_donk_event_metrics(\n",
    "                df[df['in_position']],\n",
    "                responses_df[responses_df['bettor_in_position']],\n",
    "                exclude_special=exclude_special,\n",
    "            ),\n",
    "            f\"{title_prefix} (In Position)\",\n",
    "        ),\n",
    "        (\n",
    "            _prepare_donk_event_metrics(\n",
    "                df[~df['in_position']],\n",
    "                responses_df[~responses_df['bettor_in_position']],\n",
    "                exclude_special=exclude_special,\n",
    "            ),\n",
    "            f\"{title_prefix} (Out of Position)\",\n",
    "        ),\n",
    "    ]\n",
    "    for metrics_slice, label in subsets:\n",
    "        if metrics_slice is None or metrics_slice.empty:\n",
    "            continue\n",
    "        _display_donk_event_tables(metrics_slice, label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203b7a62",
   "metadata": {},
   "source": [
    "### Flop Event-Level Outcomes\n",
    "\n",
    "These tables mirror the turn explorer value/fold summaries.\n",
    "They exclude one big blind probes and all-in bets, summarising villain\n",
    "contributions in pot-percent terms for easier sizing comparisons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310fd43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df.empty or responses_df.empty:\n",
    "    print('No flop events or responses available for event-level analysis.')\n",
    "else:\n",
    "    display_donk_event_ev_tables()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5d738b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not responses_df.empty:\n",
    "    summary_responses = summarize_responses_df(responses_df, BUCKETS)\n",
    "    display_response_tables(summary_responses, \"Responses to Donk Bets\", source_df=responses_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966bd22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not responses_df.empty:\n",
    "    display_response_for_mask(responses_df['bettor_in_position'], 'Responses vs In-Position Donk Bets')\n",
    "    display_response_for_mask(~responses_df['bettor_in_position'], 'Responses vs Out-of-Position Donk Bets')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820fa862",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not responses_df.empty:\n",
    "    def response_flop_group(count):\n",
    "        if count <= 2:\n",
    "            return '2 Players'\n",
    "        if count == 3:\n",
    "            return '3 Players'\n",
    "        return '4+ Players'\n",
    "\n",
    "    responses_df['flop_group'] = responses_df['flop_players'].apply(response_flop_group)\n",
    "\n",
    "    response_group_titles = [\n",
    "        ('2 Players', 'Responses (2 Players)'),\n",
    "        ('3 Players', 'Responses (3 Players)'),\n",
    "        ('4+ Players', 'Responses (4 Players)'),\n",
    "    ]\n",
    "\n",
    "    for group_key, title in response_group_titles:\n",
    "        mask = responses_df['flop_group'] == group_key\n",
    "        if mask.any():\n",
    "            display_response_for_mask(mask, title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e17221",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not responses_df.empty:\n",
    "    raise_rows = responses_df[responses_df['response'] == 'Raise']\n",
    "    if raise_rows.empty:\n",
    "        print('No raise responses recorded.')\n",
    "    else:\n",
    "        raise_records = []\n",
    "        for _, row in raise_rows.iterrows():\n",
    "            primary = row.get('responder_primary')\n",
    "            if not primary:\n",
    "                continue\n",
    "            raise_records.append(\n",
    "                {\n",
    "                    'ratio': float(row['ratio']),\n",
    "                    'primary': primary,\n",
    "                    'has_flush_draw': bool(row.get('responder_has_flush_draw')),\n",
    "                    'has_oesd_dg': bool(row.get('responder_has_oesd_dg')),\n",
    "                }\n",
    "            )\n",
    "        if raise_records:\n",
    "            raise_primary_groups = {cat: [cat] for cat in available_primary_categories(raise_records)}\n",
    "            raise_draw_flags = {\n",
    "                'Flush Draw': 'has_flush_draw',\n",
    "                'OESD/DG': 'has_oesd_dg',\n",
    "            }\n",
    "            raise_summary = summarize_events(raise_records, BUCKETS, raise_primary_groups, raise_draw_flags)\n",
    "            print(\"Opponent holdings when they raise the hero's donk bet (bucketed by hero's sizing).\")\n",
    "            display_heatmap_tables(\n",
    "                raise_summary,\n",
    "                'Opponent Raise Holdings vs Hero Donk Bet',\n",
    "                base_color='#cb181d',\n",
    "                group_color='#88419d',\n",
    "            )\n",
    "        else:\n",
    "            print('Raise responses lack classified hands.')\n",
    "    call_rows = responses_df[responses_df['response'] == 'Call']\n",
    "    if call_rows.empty:\n",
    "        print('No call responses recorded.')\n",
    "    else:\n",
    "        call_records = []\n",
    "        for _, row in call_rows.iterrows():\n",
    "            primary = row.get('responder_primary')\n",
    "            if not primary:\n",
    "                continue\n",
    "            call_records.append(\n",
    "                {\n",
    "                    'ratio': float(row['ratio']),\n",
    "                    'primary': primary,\n",
    "                    'has_flush_draw': bool(row.get('responder_has_flush_draw')),\n",
    "                    'has_oesd_dg': bool(row.get('responder_has_oesd_dg')),\n",
    "                }\n",
    "            )\n",
    "        if call_records:\n",
    "            call_primary_groups = {cat: [cat] for cat in available_primary_categories(call_records)}\n",
    "            call_draw_flags = {\n",
    "                'Flush Draw': 'has_flush_draw',\n",
    "                'OESD/DG': 'has_oesd_dg',\n",
    "            }\n",
    "            call_summary = summarize_events(call_records, BUCKETS, call_primary_groups, call_draw_flags)\n",
    "            print(\"Opponent holdings when they call the hero's donk bet (bucketed by hero's sizing).\")\n",
    "            display_heatmap_tables(\n",
    "                call_summary,\n",
    "                'Opponent Call Holdings vs Hero Donk Bet',\n",
    "                base_color='#2171b5',\n",
    "                group_color='#6baed6',\n",
    "            )\n",
    "        else:\n",
    "            print('Call responses lack classified hands.')\n",
    "\n",
    "    if turn_events:\n",
    "        display_turn_response_holdings(turn_events, turn_responses, 'Barrel', 'Raise', 'Opponent Raise Holdings vs Hero Barrel', base_color='#cb181d', group_color='#88419d')\n",
    "        display_turn_response_holdings(turn_events, turn_responses, 'Delayed', 'Raise', 'Opponent Raise Holdings vs Hero Delayed Donk Bet', base_color='#cb181d', group_color='#88419d')\n",
    "        display_turn_response_holdings(turn_events, turn_responses, 'Barrel', 'Call', 'Opponent Call Holdings vs Hero Barrel', base_color='#2171b5', group_color='#6baed6')\n",
    "        display_turn_response_holdings(turn_events, turn_responses, 'Delayed', 'Call', 'Opponent Call Holdings vs Hero Delayed Donk Bet', base_color='#2171b5', group_color='#6baed6')\n",
    "else:\n",
    "    print('No donk bet response events available.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fc3ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "DRAW_FIELDS = [\n",
    "    ('Flush Draw', 'responder_has_flush_draw'),\n",
    "    ('OESD/DG', 'responder_has_oesd_dg'),\n",
    "]\n",
    "\n",
    "def _summarize_holdings(responses_subset):\n",
    "    classified = responses_subset.dropna(subset=['responder_primary'])\n",
    "    if classified.empty:\n",
    "        return None\n",
    "    total = len(classified)\n",
    "    cat_counts = {cat: int((classified['responder_primary'] == cat).sum()) for cat in BASE_PRIMARY_CATEGORIES}\n",
    "\n",
    "    base_index = ['Events'] + BASE_PRIMARY_CATEGORIES + [label for label, _ in DRAW_FIELDS]\n",
    "    base_values = []\n",
    "    for entry in base_index:\n",
    "        if entry == 'Events':\n",
    "            base_values.append(float(total))\n",
    "        elif entry in BASE_PRIMARY_CATEGORIES:\n",
    "            base_values.append(cat_counts.get(entry, 0) / total * 100 if total else 0.0)\n",
    "        else:\n",
    "            field = dict(DRAW_FIELDS)[entry]\n",
    "            base_values.append(classified[field].mean() * 100 if total else 0.0)\n",
    "    base_series = pd.Series(base_values, index=base_index, dtype=float)\n",
    "\n",
    "    any_draw_pct = (classified['responder_has_flush_draw'] | classified['responder_has_oesd_dg']).mean() * 100 if total else 0.0\n",
    "    group_index = ['Events'] + [label for label, members in GROUPED_PRIMARY_ORDER if members is not None]\n",
    "    group_values = []\n",
    "    for label in group_index:\n",
    "        if label == 'Events':\n",
    "            group_values.append(float(total))\n",
    "        elif label == 'Draw':\n",
    "            group_values.append(any_draw_pct)\n",
    "        else:\n",
    "            members = dict(GROUPED_PRIMARY_ORDER).get(label, [])\n",
    "            group_values.append(sum(cat_counts.get(member, 0) for member in members) / total * 100 if total else 0.0)\n",
    "    group_series = pd.Series(group_values, index=group_index, dtype=float)\n",
    "    return base_series, group_series\n",
    "\n",
    "if responses_df.empty:\n",
    "    print('No donk bet response events available.')\n",
    "else:\n",
    "    raise_rows = responses_df[responses_df['response'] == 'Raise']\n",
    "    call_rows = responses_df[responses_df['response'] == 'Call']\n",
    "\n",
    "    raise_summary = _summarize_holdings(raise_rows) if not raise_rows.empty else None\n",
    "    call_summary = _summarize_holdings(call_rows) if not call_rows.empty else None\n",
    "\n",
    "    if not raise_summary and not call_summary:\n",
    "        print('No raise or call responses with classified hands.')\n",
    "    else:\n",
    "        base_columns = []\n",
    "        if raise_summary:\n",
    "            base_columns.append(('Donk Bet Raise Holdings (%)', raise_summary[0]))\n",
    "        if call_summary:\n",
    "            base_columns.append(('Donk Bet Call Holdings (%)', call_summary[0]))\n",
    "\n",
    "        if base_columns:\n",
    "            base_df = pd.concat([series.rename(col) for col, series in base_columns], axis=1)\n",
    "            base_df = base_df.reindex(['Events'] + BASE_PRIMARY_CATEGORIES + [label for label, _ in DRAW_FIELDS])\n",
    "            styler = base_df.style\n",
    "            value_rows = base_df.index.difference(['Events'])\n",
    "            if not value_rows.empty:\n",
    "                styler = styler.background_gradient(\n",
    "                    cmap=_gradient_cmap('#d95f02'),\n",
    "                    axis=None,\n",
    "                    subset=pd.IndexSlice[value_rows, base_df.columns]\n",
    "                )\n",
    "            styler = (\n",
    "                styler\n",
    "                .format('{:.0f}', subset=pd.IndexSlice[['Events'], base_df.columns])\n",
    "                .format('{:.1f}%', subset=pd.IndexSlice[value_rows, base_df.columns])\n",
    "                .set_caption('Donk Bet Raise vs Call Holdings')\n",
    "            )\n",
    "            display(styler)\n",
    "\n",
    "        group_columns = []\n",
    "        if raise_summary:\n",
    "            group_columns.append(('Donk Bet Raise Holdings (%)', raise_summary[1]))\n",
    "        if call_summary:\n",
    "            group_columns.append(('Donk Bet Call Holdings (%)', call_summary[1]))\n",
    "\n",
    "        if group_columns:\n",
    "            group_df = pd.concat([series.rename(col) for col, series in group_columns], axis=1)\n",
    "            group_df = group_df.reindex(['Events'] + [label for label, members in GROUPED_PRIMARY_ORDER if members is not None])\n",
    "            group_styler = group_df.style\n",
    "            group_value_rows = group_df.index.difference(['Events'])\n",
    "            if not group_value_rows.empty:\n",
    "                group_styler = group_styler.background_gradient(\n",
    "                    cmap=_gradient_cmap('#3182bd'),\n",
    "                    axis=None,\n",
    "                    subset=pd.IndexSlice[group_value_rows, group_df.columns]\n",
    "                )\n",
    "            group_styler = (\n",
    "                group_styler\n",
    "                .format('{:.0f}', subset=pd.IndexSlice[['Events'], group_df.columns])\n",
    "                .format('{:.1f}%', subset=pd.IndexSlice[group_value_rows, group_df.columns])\n",
    "                .set_caption('Donk Bet Raise vs Call Holdings (Grouped)')\n",
    "            )\n",
    "            display(group_styler)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}